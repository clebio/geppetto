{
  "completion": [
    {
      "name": "text-davinci-003",
      "family": "davinci",
      "description": "Most capable GPT-3 model. Can do any task the other models can do, often with higher quality, longer output and better instruction-following. Also supports inserting completions within text.",
      "max_tokens": 4000,
      "training_data_cutoff_date": "2021-06"
    },
    {
      "name": "text-curie-001",
      "family": "curie",
      "description": "Very capable, but faster and lower cost than Davinci.",
      "max_tokens": 2048,
      "training_data_cutoff_date": "2019-10"
    },
    {
      "name": "text-babbage-001",
      "family": "babbage",
      "description": "Capable of straightforward tasks, very fast, and lower cost.",
      "max_tokens": 2048,
      "training_data_cutoff_date": "2019-10"
    },
    {
      "name": "text-ada-001",
      "family": "ada",
      "description": "Capable of very simple tasks, usually the fastest model in the GPT-3 series, and lowest cost.",
      "max_tokens": 2048,
      "training_data_cutoff_date": "2019-10"
    }
  ],
  "families": [
    {
      "name": "davinci",
      "description": "Davinci is the most capable model family and can perform any task the other models can perform and often with less instruction. For applications requiring a lot of understanding of the content, like summarization for a specific audience and creative content generation, Davinci is going to produce the best results. These increased capabilities require more compute resources, so Davinci costs more per API call and is not as fast as the other models.",
      "price_per_1k_tokens": 0.0200,
      "good_at": [
        "Complex intent",
        "Cause and effect",
        "Summarization for audience"
      ],
      "key_points": [
        "Most capable model family",
        "Can perform any task the other models can perform",
        "Often with less instruction",
        "Best results for complex content",
        "Higher cost and slower than other models",
        "Good at understanding the intent of text",
        "Good at solving logic problems",
        "Good at explaining motives of characters"
      ],
      "short": "Davinci is the most capable model family with increased capabilities and more compute resources.",
      "subtitle": "The Most Capable Model Family"
    },
    {
      "name": "curie",
      "description": "Curie is extremely powerful, yet very fast. While Davinci is stronger when it comes to analyzing complicated text, Curie is quite capable for many nuanced tasks like sentiment classification and summarization. Curie is also quite good at answering questions and performing Q&A and as a general service chatbot.",
      "price_per_1k_tokens": 0.0020,
      "good_at": [
        "Language translation",
        "Complex classification",
        "Text sentiment",
        "Summarization"
      ],
      "key_points": [
        "Extremely powerful",
        "Very fast",
        "Strong for nuanced tasks",
        "Good at sentiment classification and summarization",
        "Good at answering questions",
        "Good as a general service chatbot"
      ],
      "short": "Extremely powerful and fast for sentiment classification, summarization, Q&A, and general service chatbot.",
      "subtitle": "A Powerful and Fast Model Family"
    },
    {
      "name": "babbage",
      "description": "Babbage can perform straightforward tasks like simple classification. It’s also quite capable when it comes to Semantic Search ranking how well documents match up with search queries.",
      "price_per_1k_tokens": 0.0005,
      "good_at": [
        "Moderate classification",
        "Semantic search classification"
      ],
      "key_points": [
        "Can perform straightforward tasks",
        "Good at simple classification",
        "Good at semantic search classification",
        "Capable for ranking documents in semantic search"
      ],
      "subtitle": "Simple Classification and Semantic Search Ranking",
      "short": "Babbage can perform straightforward tasks like simple classification as well as Semantic Search ranking."
    },
    {
      "name": "ada",
      "description": "Ada is usually the fastest model and can perform tasks like parsing text, address correction and certain kinds of classification tasks that don’t require too much nuance. Ada’s performance can often be improved by providing more context.",
      "price_per_1k_tokens": 0.0004,
      "good_at": [
        "Parsing text",
        "Simple classification",
        "Address correction",
        "Keywords"
      ],
      "key_points": [
        "Usually the fastest model",
        "Good at parsing text",
        "Good at simple classification",
        "Good at address correction",
        "Performance can be improved by providing more context"
      ],
      "subtitle": "The Fastest Model",
      "short": "Ada is usually the fastest model and can perform certain tasks with improved performance when provided with more context."
    }
  ]
}