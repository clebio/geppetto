# LOG 2023-02-04

Today, I want to work on something "pretty" simple. I have a markdown file
with an article, a series of titles and paragraphs. I want to query the GPT3
with each paragraph.

I wrote a little `markdown split-by-heading` command for glaze:

```
glazed on ÓÇ† task/112/add-markdown-input-parser via üêπ v1.19.4 on ‚òÅÔ∏è  ttc (us-east-1) took 28s 
‚ùØ go run ./cmd/glaze  markdown split-by-heading /tmp/test2.md --output json --level 3
[
  {
    "content": "bla",
    "heading": "test"
  },
  {
    "content": "blabla",
    "heading": "test2"
  }
]%                                                                                                                       
glazed on ÓÇ† task/112/add-markdown-input-parser via üêπ v1.19.4 on ‚òÅÔ∏è  ttc (us-east-1) 
‚ùØ cat /tmp/test2.md 
# foo

## bla

### test

bla

### test2

blabla

```

That's nice, but I now need to figure out how to run this nicely with pinocchio, without
having to do a lot of manual work.

This would be the first example of a real loop chain step.

I could write a manual loop chain for now, that loads a json and a template from a markdown file,
but at this point I will have to think about the geppetto bundle format.

## YAML / app bundle format

I think it makes sense for steps to have a preprocess and postprocess chain 
that is not actual steps, because they wouldn't need IO, and because it would be 
confusing for users anyway. Instead, a set of nice utilities that can be piped into each
other to clean up the input and output. This is where the parsers would live, and
potentially a way to handle the prompt rendering.

So overall the syntax could be a bit like:

```yaml 
steps:
  questions:
    # this is basically instantiating a custom node with a certain map type for input
    # and a certain type for output
    type: multi
    prompt: templates/questions.tmpl.txt
    input:
      article:
        type: string
        description: Markdown article with h2 sections
        name: article
        process: split-by-heading
      questions:
        type: string_list
        description: List of questions to ask about each section
    output:
      # here we could actually already postprocess the answers to include
      # the question and the paragraph, assuming that the postprocess step has
      # access to the inputs, the outputs.
      #
      # larger context is wired through "inputs". Potentially this can be an actual object
      # and the template can leverage calling function for quick lookup or setting status (??)
      type: string_list
  summarize:
    type: simple
    prompt: templates/summarize.yaml
  combine_answers:
    type: merge
    template: templates/answers.yaml
    input:
      article:
        type: string
        description: Markdown article with h2 sections
        name: article
      answers:
        type:
          type: string_list
          description: Answers gotten in the answers step
chain:
  pipe:
    - step: questions
      id: questions
      inputs:
        article: arguments.article
        questions: flags.questions
    - step: combine_answers
      id: combine-answers
      inputs:
        article: arguments.article
        answers: steps.questions.output
      template: templates/combine-with-article.yaml
    - step: summarize
      inputs:
```

So if we bring this back to what I want to write today, which is a simple multi node...

The current API we have is:

```go
package steps

import "context"

// Step represents one step in a geppetto pipeline
type Step[A, B any] interface {
    Start(ctx context.Context, a A) error
    GetOutput() <-chan helpers.Result[B]
    GetState() interface{}
    IsFinished() bool
}

```

In our context, A would be a map with article and questions values.
The step itself would have a processing chain.
The Step should have a constructor method for creating A out of a hashmap,
and we then need to have a method to instantiate the Step.
That's where the StepFactory comes into play. I don't think Step needs to know about A,
but the step factory needs to.

In fact, the step factory is potentially the one that knows how to do all the preprocessing
to make it easier on the Step. In our case, the step really just needs to have a list of prompts
and run those against openai, while the stepfactory is the one that can weave all the stuff together.


